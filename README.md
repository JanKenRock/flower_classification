# flower_classification

**Abstract** *We train the pretrained ResNet50 model on a dataset consisting of images of classes of flowers. Given an image of an arbitrary flower from any of these classes, the resulting model will be able to predict - with a certain accuracy - which exact class the flower belongs to.*

We train a neural network to classify images of different types of flowers. Instead of training a new neural network from scratch we make use of the concept of transfer learning. In transfer learning, a pretrained model, which has been trained previously for a specific task, is fine-tuned for a new but related task. This is achieved by freezing early layers and retraining only the later layers of the pretrained model. In this way, much of the knowledge the model had gained during its original training is preserved. For example, when a model is trained to classify images of cars, it often learns to extract low-level features such as edges or local textures in its early layers. But if the model is later retrained to classify images of busses, the extraction of such general features is likely to be still useful. The preservation of the knowledge of the pretrained model leads to an essential advantage in transfer learning. Namely, starting from a pretrained model typically requires much smaller amounts of data, computational resources and time to achieve similar results as in the training of an entirely new model.
